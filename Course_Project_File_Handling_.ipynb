{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jatingpt/file_handling_project/blob/main/Course_Project_File_Handling_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEk36hiNTbfE"
      },
      "source": [
        "# Introduction\n",
        "Efficient management of product information is essential for the success of e-commerce businesses. This information enables informed decision-making and facilitates effective marketing strategies. File handling plays a key role in being able to manage such data, and Python allows us to handle various file formats which are used to store such data.\n",
        "\n",
        "In this project, we are going to learn how to load, modify, and save files of three popular file formats which are used in the industry to handle data. These formats are:\n",
        "\n",
        "- **CSV**: CSV or comma-separated value files come with the file suffix *.csv* and, as the name suggests, have data values separated by commas. Each data entry is placed on a new line, and typically, the first line tends to store the names of columns. In our dataset, a CSV file is used to store sales values for each product over 14 days.\n",
        "\n",
        "- **JSON**: JSON or JavaScript object notation files come with the file suffix *.json* and store data as key-value pairs, similar to dictionaries in Python. In our dataset, JSON files are used to store details such as product names, prices, and brands.\n",
        "\n",
        "- **TXT**: TXT or text files come with the file suffix *.txt* and generally useful for storing single variables like strings or integers. In our dataset, TXT files are used to store descriptions of products."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bIkNbC2z8oL"
      },
      "source": [
        "# Problem Statement\n",
        "The goal is to read data from popular file formats (.csv, .txt, .json), to perform operations on this data, and to finally save this modified data into the original file formats."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Description\n",
        "The dataset for this project has been provided in the *mainfolder.zip* file. It contains data about products for which the unique ID provided is the stock keeping unit or SKU for short. The ZIP file contains a structured collection of sales data and product information organized into a main folder with three key components:\n",
        "\n",
        "- **Sales Data** (*sales_data.csv*): A CSV file that includes sales data for various products over a 14-day period. Each row corresponds to a different product, identified by a *Product_SKU*. The columns *Day1* through *Day14* represent the sales figures for each consecutive day.\n",
        "\n",
        "- **Product Descriptions** (*product_descriptions* folder): This folder contains text files, each corresponding to a specific product identified by the SKU in the filename (e.g., *description_AISJDKFJW93NJ.txt*). These files provide descriptive information about the products.\n",
        "\n",
        "- **Product Details** (*product_details* folder): This folder includes JSON files, again with filenames corresponding to product SKUs (e.g., *details_AISJDKFJW93NJ.json*). These files contain detailed attributes of the products, such as specifications, category, pricing, etc.\n",
        "\n",
        "This dataset is suitable for analyzing daily sales performance of products, supplemented with detailed product information and descriptions to allow for a comprehensive analysis of sales trends in relation to product attributes and descriptions."
      ],
      "metadata": {
        "id": "hJ1m6tWtIhXS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCi_8EQ_SKh2"
      },
      "source": [
        "# Outline\n",
        "The overall objective of this project is to create a system for managing product information in an e-commerce platform. The different stages involved in the process are outlined below:\n",
        "\n",
        "- Stage 1 - Set up project and load data\n",
        "    - Task 1 - Import required modules\n",
        "    - Task 2 - Load the data\n",
        "- Stage 2 - Create or update data\n",
        "    - Task 3 - Add or update sales data\n",
        "    - Task 4 - Add or update product details\n",
        "    - Task 5 - Add or update product description\n",
        "    - Task 6 - Update function\n",
        "- Stage 3 - Save data to disk\n",
        "    - Task 7 - Save data to disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSDjItPDapX4"
      },
      "source": [
        "# Stage 1 - Set up project and load data\n",
        "In this stage, i am setting up the environment for this assignment by loading the required modules and files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fwAly7Kc9ei"
      },
      "source": [
        "## Task 1 - Importing required modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hjXLR-lwERP"
      },
      "source": [
        "Importing the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uKKJxfEj6o1C"
      },
      "outputs": [],
      "source": [
        "#importing all the packages and libraries.\n",
        "import os          #for navigating the file directories.\n",
        "import json\n",
        "import csv\n",
        "import pandas as pd   #to run csv file effeciently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOLRp-Ydph2X"
      },
      "source": [
        "## Task 2 - Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3LqSPrspl8b"
      },
      "source": [
        "### Description\n",
        "In this task, I have written a function that ensures that the necessary files are loaded into the environment. To index the data, I have used a unique identifier called SKU.\n",
        "\n",
        "This includes loading sales data from a CSV file, product details from JSON files, and product descriptions from text files. I will be using Google Colab to build and execute code."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Implementing loading the data**"
      ],
      "metadata": {
        "id": "ZrEEH-zyVW6h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lfU3Pq-67sn"
      },
      "source": [
        "### Recommendations\n",
        "- If you are using Google Colab:\n",
        "  - Upload the zip file containing the files in Google Drive or upload the zip file directly to the Google Colab runtime.\n",
        "    - Then unzip it using `unzip` shell command which you can access using the `!` (exclamation mark) character.\n",
        "  - Once you have mounted Google Drive into your Google Colab VM or uploaded the zip file directly to the Google Colab runtime.\n",
        "    - You can use the *Files* section on the left to access the filesystem. You can right click on a file or folder to copy its path. This will be useful while specifying the source file in the `unzip` shell command.\n",
        "  - You will need to pass the location of the main folder into the `load_data()` function to load *sales_data.csv* file and the files in *product_details* and *product_description* folders.\n",
        "- Inside the `load_data()` function, you can:\n",
        "    - use the `csv.DictReader()` method to read the *sales_data.csv* file, and to store the data as dictionaries with key-value pairs where the keys correspond to the column names in the first row,\n",
        "    - use the `os.listdir()` method to obtain the names of the files and folders within a particular folder,\n",
        "    - use `os.path.join()` to construct file paths,\n",
        "    - use the `json.load()` method to load JSON files, and\n",
        "    - use the `open()` function to load the text files.\n",
        "-  As you need to use the SKUs as keys in all three dictionaries, you can ask a generative AI tool like ChatGPT on how to extract the SKU values in all three cases.\n",
        "    - In *sales_data.csv* they have been saved in a column titled *Product_SKU*\n",
        "    - For the other two, you need to extract the SKU from the file name: you must obtain the SKU which lies between the prefix and the suffix. Try using the in-built string function `split()` (additionally, you can use `replace()` if you wish to write the code in one line).\n",
        "    - Provide the data description and requirements to ChatGPT along with the libraries that you are using and ask it to generate code for the function.\n",
        "    - If you get stuck somewhere, you can ask ChatGPT to explain the code to you and you can make edits as required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQRLEoiZ-QxY"
      },
      "source": [
        "First, if you are using Google Colab, mount Google Drive to your VM. If not, skip and comment out this cell."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#uploading the zip file in my google colab enviornment.\n",
        "\n",
        "\n",
        "!ls -lh           #to check if mainfolder.zip file exists\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "!ls -lh\n",
        "\n",
        "!unzip -q mainfolder.zip -d main_folder_location       #unzipping the file\n",
        "\n",
        "!ls main_folder_location/mainfolder #Verify the Extracted Files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "2DleCdYIUVss",
        "outputId": "b30f21d0-8c0c-401e-94b7-276e8e1671c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12K\n",
            "drwxr-xr-x 2 root root 4.0K Mar 11 08:08 mainfolder\n",
            "drwxr-xr-x 3 root root 4.0K Mar 11 08:09 main_folder_location\n",
            "drwxr-xr-x 1 root root 4.0K Mar  7 14:26 sample_data\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-970ffdc5-c284-4b5e-82f3-14df4bf7a5ad\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-970ffdc5-c284-4b5e-82f3-14df4bf7a5ad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mainfolder.zip to mainfolder.zip\n",
            "total 24K\n",
            "drwxr-xr-x 2 root root 4.0K Mar 11 08:08 mainfolder\n",
            "drwxr-xr-x 3 root root 4.0K Mar 11 08:09 main_folder_location\n",
            "-rw-r--r-- 1 root root 9.4K Mar 11 08:30 mainfolder.zip\n",
            "drwxr-xr-x 1 root root 4.0K Mar  7 14:26 sample_data\n",
            "replace main_folder_location/mainfolder/sales_data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "product_descriptions  product_details  sales_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that this works and product_descriptions, product_details and sales_data.csv come as a result.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Q_cYWaoWQVH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiYKN_QJlRBE"
      },
      "source": [
        "Now define the *load_data()* function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lh8skyqy7Qb6",
        "outputId": "607b6d26-ae95-4bf3-d19e-1fa20007bd28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Columns: ['Product_SKU', 'Day1', 'Day2', 'Day3', 'Day4', 'Day5', 'Day6', 'Day7', 'Day8', 'Day9', 'Day10', 'Day11', 'Day12', 'Day13', 'Day14']\n",
            "Product Details Sample: [('details_DJKFIEI432FIE', {'product_name': \"Men's Running Shoes\", 'brand': 'RunFit', 'model': 'SpeedX-500', 'specifications': 'Size 10, Lightweight design, Breathable material', 'price': '$79.99', 'availability': 'In stock'}), ('details_NEKFJOWE9FDIW', {'product_name': 'Board Game', 'brand': 'FamilyFun', 'model': 'GameNight-2022', 'specifications': '2-6 players, Ages 8 and up', 'price': '$29.99', 'availability': 'In stock'})]\n",
            "Sales Data Sample: [('SKU_001', [10, 12, 15, 20, 8, 5, 9, 11, 13, 14, 7, 6, 8, 10]), ('SKU_002', [5, 8, 6, 7, 12, 15, 14, 10, 9, 11, 8, 5, 7, 6])]\n",
            "Product Descriptions Sample: [('description_XPLFJW2490XJN', 'Introducing the CleanTech AutoSweep-9000 Robot Vacuum Cleaner â€“ your smart companion for automated cleaning.\\nWith smart navigation, a HEPA filter, and a runtime of 90 minutes, this efficient device takes care of your cleaning needs.\\nAvailable in White and Silver, it blends seamlessly into your home, making cleanliness a hassle-free experience.'), ('description_DJKFIEI432FIE', \"Elevate your running experience with the RunFit SpeedX-500 Men's Running Shoes.\\nDesigned for performance, these shoes feature a lightweight design, breathable material, and are available in vibrant Red, Blue, and classic Black.\\nWhether you're a seasoned runner or just starting, these shoes provide comfort and support for every stride, ensuring you reach new milestones effortlessly.\")]\n"
          ]
        }
      ],
      "source": [
        "# def load_data(main_folder):\n",
        "#     \"\"\"\n",
        "#     Load product details, sales data, and product descriptions from files within the specified zip file.\n",
        "\n",
        "#     Parameters:\n",
        "#         main_folder (str): The path to the zip file containing the dataset.\n",
        "\n",
        "#     Returns:\n",
        "#         tuple: A tuple containing three dictionaries:\n",
        "#             - product_details (dict): A dictionary of dictionaries where keys are product SKUs (extracted from the filenames of the JSON files)\n",
        "#               and values are product details loaded from the JSON files.\n",
        "#             - sales_data (dict): A dictionary where keys are product SKUs (from the CSV file) and values are lists\n",
        "#               of quantities corresponding to sales data.\n",
        "#             - product_descriptions (dict): A dictionary where keys are product SKUs (extracted from the filenames of the TXT files)\n",
        "#               and values are product descriptions loaded from TXT files.\n",
        "#    \"\"\"\n",
        "\n",
        "### CODE HERE ###\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(main_folder):\n",
        "    \"\"\"\n",
        "    Load product details, sales data, and product descriptions from files within the specified main folder.\n",
        "\n",
        "    Parameters:\n",
        "        main_folder (str): The path to the extracted folder containing the dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing three dictionaries:\n",
        "            - product_details (dict): A dictionary of dictionaries where keys are product SKUs (extracted from the filenames of the JSON files)\n",
        "              and values are product details loaded from the JSON files.\n",
        "            - sales_data (dict): A dictionary where keys are product SKUs (from the CSV file) and values are lists\n",
        "              of quantities corresponding to sales data.\n",
        "            - product_descriptions (dict): A dictionary where keys are product SKUs (extracted from the filenames of the TXT files)\n",
        "              and values are product descriptions loaded from TXT files.\n",
        "    \"\"\"\n",
        "\n",
        "    # Paths to subfolders\n",
        "    json_dir = os.path.join(main_folder, \"product_details\")\n",
        "    txt_dir = os.path.join(main_folder, \"product_descriptions\")\n",
        "    csv_path = os.path.join(main_folder, \"sales_data.csv\")\n",
        "\n",
        "    # Load Product Details (JSON)\n",
        "    product_details = {}\n",
        "    if os.path.exists(json_dir):\n",
        "        for file in os.listdir(json_dir):\n",
        "            if file.endswith('.json'):\n",
        "                sku = os.path.splitext(file)[0]  # Extract SKU from filename\n",
        "                with open(os.path.join(json_dir, file), 'r', encoding='utf-8') as f:\n",
        "                    product_details[sku] = json.load(f)\n",
        "\n",
        "    # Load Sales Data (CSV)\n",
        "    sales_data = {}\n",
        "    if os.path.exists(csv_path):\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Print column names for debugging\n",
        "        print(\"CSV Columns:\", df.columns.tolist())\n",
        "\n",
        "        # Standardizing column names (removes extra spaces)\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        # Ensure we use the correct SKU column\n",
        "        sku_column = \"Product_SKU\"\n",
        "        if sku_column not in df.columns:\n",
        "            raise KeyError(f\"SKU column '{sku_column}' not found! Available columns: {df.columns.tolist()}\")\n",
        "\n",
        "        # Extract sales quantities (Day1 to Day14)\n",
        "        sales_columns = [col for col in df.columns if \"Day\" in col]\n",
        "\n",
        "        # Load sales data into a dictionary\n",
        "        for _, row in df.iterrows():\n",
        "            sku = str(row[sku_column])  # Convert SKU to string\n",
        "            quantities = row[sales_columns].tolist()  # Get sales values as a list\n",
        "            sales_data[sku] = quantities\n",
        "\n",
        "    # Load Product Descriptions (TXT)\n",
        "    product_descriptions = {}\n",
        "    if os.path.exists(txt_dir):\n",
        "        for file in os.listdir(txt_dir):\n",
        "            if file.endswith('.txt'):\n",
        "                sku = os.path.splitext(file)[0]  # Extract SKU from filename\n",
        "                with open(os.path.join(txt_dir, file), 'r', encoding='utf-8') as f:\n",
        "                    product_descriptions[sku] = f.read().strip()\n",
        "\n",
        "    return product_details, sales_data, product_descriptions\n",
        "\n",
        "# Example usage\n",
        "main_folder = \"main_folder_location/mainfolder\"\n",
        "product_details, sales_data, product_descriptions = load_data(main_folder)\n",
        "\n",
        "# Display sample outputs\n",
        "print(\"Product Details Sample:\", list(product_details.items())[:2])\n",
        "print(\"Sales Data Sample:\", list(sales_data.items())[:2])  # Now contains lists of sales quantities\n",
        "print(\"Product Descriptions Sample:\", list(product_descriptions.items())[:2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRjwNJj67LP_"
      },
      "source": [
        "Load your data here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mkeH5Ba17Qmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa213c95-27b1-4d67-fab9-1d45f953ad71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV Columns: ['Product_SKU', 'Day1', 'Day2', 'Day3', 'Day4', 'Day5', 'Day6', 'Day7', 'Day8', 'Day9', 'Day10', 'Day11', 'Day12', 'Day13', 'Day14']\n"
          ]
        }
      ],
      "source": [
        "# Use this cell to load the files\n",
        "main_folder_address = '/content/mainfolder'\n",
        "product_details, sales_data, product_descriptions = load_data(main_folder_address)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf3FIRGg_G2b"
      },
      "source": [
        "### Checklist\n",
        "- Defined the `load_data()` function which takes in the given keyword arguments and returns the given variables.\n",
        "- Used the `load_data()` function to load data into `sales_data`, `product_details` and `product_descriptions`.\n",
        "- `sales_data, product_details` and `product_descriptions` are of the type `dict`.\n",
        "- Items in `sales_data, product_details`, and `product_descriptions` are as follows:\n",
        "    - `sales_data` contains product SKUs mapped to lists of whole numbers representing the amount of product sold per day,\n",
        "    - `product_details` contains product SKUs mapped to dictionaries containing various details such as product name, brand, model, specifications, price, and availability, and\n",
        "    - `product_descriptions` contains product SKUs mapped to strings representing descriptions of the corresponding products."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s3el3T2A41B"
      },
      "source": [
        "# Stage 2 - Update data\n",
        "In this stage, you will define a function `update()` to add sales data, product details, and product descriptions for a new product or update an existing product. If the product does not exist, the function will default to creating a new product. If the product exists, the function will instead update that product. You will also define some sub-functions to complete smaller tasks.\n",
        "\n",
        "You will achieve this by completing the following tasks:\n",
        "- Task 3 - Update sales data\n",
        "- Task 4 - Update product details\n",
        "- Task 5 - Update product description\n",
        "- Task 6 - Update function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KR9w5MtF2iuy"
      },
      "source": [
        "## Task 3 - Update sales data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sv3srpNP0by"
      },
      "source": [
        "### Description\n",
        "In this task, you will write a function to add sales data for a new product or update sales data for an existing product given the SKU and the quantities that need to be added or updated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuS0kGCbP93D"
      },
      "source": [
        "### Requirements\n",
        "- Define a function named `update_sales_data()` that:\n",
        "  - Adds new sales data or updates existing sales data to the `sales_data` dicitionary using the SKU as a key.\n",
        "  - The function should accept the following parameters:\n",
        "    - the `sales_data` dictionary,\n",
        "    - the `sku` value, and\n",
        "    - a list called `quantities` consisting of numeric sales data.\n",
        "- The function should return:\n",
        "    - The updated `sales_data` dictionary after creating the entry for the new SKU or updating the entry for an existing SKU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RdPeCXd22MJ5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_sales_data(sales_data, sku, quantities):\n",
        "    \"\"\"\n",
        "    Updates the sales_data dictionary by adding or updating sales data for a given SKU.\n",
        "\n",
        "    Parameters:\n",
        "        sales_data (dict): The dictionary containing sales data.\n",
        "        sku (str): The SKU of the product to be updated.\n",
        "        quantities (list): A list of numeric values representing daily sales data.\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated sales_data dictionary.\n",
        "    \"\"\"\n",
        "    if sku in sales_data:\n",
        "        # Update existing SKU: Extend the existing sales data with new quantities\n",
        "        sales_data[sku] += quantities\n",
        "    else:\n",
        "        # Add new SKU with the provided quantities\n",
        "        sales_data[sku] = quantities\n",
        "\n",
        "    return sales_data\n",
        "\n",
        "# Example Usage\n",
        "sales_data = {\n",
        "    \"SKU_001\": [10, 12, 15, 20, 8, 5, 9, 11, 13, 14, 7, 6, 8, 10],\n",
        "    \"SKU_002\": [5, 8, 6, 7, 12, 15, 14, 10, 9, 11, 8, 5, 7, 6]\n",
        "}\n",
        "\n",
        "# Update SKU_001 and add a new SKU_003\n",
        "sales_data = update_sales_data(sales_data, \"SKU_001\", [12, 15, 20])  # Update existing SKU\n",
        "sales_data = update_sales_data(sales_data, \"SKU_003\", [8, 10, 7, 12])  # Add new SKU\n",
        "\n",
        "print(sales_data)\n"
      ],
      "metadata": {
        "id": "NL0egcrj9-hD",
        "outputId": "e14ec2ad-ab1a-440f-b301-6d271ce33a3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SKU_001': [10, 12, 15, 20, 8, 5, 9, 11, 13, 14, 7, 6, 8, 10, 12, 15, 20], 'SKU_002': [5, 8, 6, 7, 12, 15, 14, 10, 9, 11, 8, 5, 7, 6], 'SKU_003': [8, 10, 7, 12]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ1PeYvAP9nI"
      },
      "source": [
        "### Checklist\n",
        "- Function `update_sales_data()` defined.\n",
        "- Modified the `sales_data` dictionary to reflect the newly added or updated product.\n",
        "- Updated `sales_data` dictionary returned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "276dzYC32PIS"
      },
      "source": [
        "## Task 4 - Update product details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I8sKosLT5sl"
      },
      "source": [
        "### Description\n",
        "In this task, you will write a function to add product details for a new product or update product details for an existing product using the product SKU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkfZCY48T5ss"
      },
      "source": [
        "### Requirements\n",
        "- Define a function named `update_product_details()` that adds new product details to or updates existing product details in the `product_details` dictionary using the SKU as the key.\n",
        "- The function should accept three parameters:\n",
        "  - the `product_details` dictionary,\n",
        "  - the `sku` value, and\n",
        "  - a dictionary called `product_info` containing the details of the product, such as product name, brand, model, specifications, price, and availability.\n",
        "- The function adds the `product_info` dictionary to the `product_details` dictionary with the provided SKU as the key if the SKU does not exist, or updates the existing entry if it does.\n",
        "- Return the updated `product_details` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uiOO_eNr2PkA"
      },
      "outputs": [],
      "source": [
        "# def update_product_details(product_details, sku, product_info):\n",
        "#     \"\"\"\n",
        "#     Create a new product/update an existing product details entry in the product details dictionary using the provided product information.\n",
        "\n",
        "#     Parameters:\n",
        "#         product_details (dict): The dictionary containing product details.\n",
        "#         sku (str): The product SKU.\n",
        "#         product_info (dict): A dictionary containing the details of the product, such as product name, brand, model, specifications, price, and availability.\n",
        "\n",
        "#     Returns:\n",
        "#         dict: The updated product details with the new or updated product entry.\n",
        "#     \"\"\"\n",
        "\n",
        "#     ### CODE HERE ###\n",
        "\n",
        "#     return product_details"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_product_details(product_details, sku, product_info):\n",
        "    \"\"\"\n",
        "    Updates the product_details dictionary by adding or updating details for a given SKU.\n",
        "\n",
        "    Parameters:\n",
        "        product_details (dict): The dictionary containing product details.\n",
        "        sku (str): The SKU of the product to be updated.\n",
        "        product_info (dict): A dictionary containing details like product name, brand, model, specifications, price, and availability.\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated product_details dictionary.\n",
        "    \"\"\"\n",
        "    if sku in product_details:\n",
        "        # Update existing product details\n",
        "        product_details[sku].update(product_info)\n",
        "    else:\n",
        "        # Add new product details\n",
        "        product_details[sku] = product_info\n",
        "\n",
        "    return product_details\n",
        "\n",
        "# Example Usage\n",
        "product_details = {\n",
        "    \"SKU_001\": {\n",
        "        \"product_name\": \"Laptop\",\n",
        "        \"brand\": \"XYZ\",\n",
        "        \"model\": \"X123\",\n",
        "        \"specifications\": {\"RAM\": \"8GB\", \"Storage\": \"512GB SSD\"},\n",
        "        \"price\": 50000,\n",
        "        \"availability\": \"In Stock\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Update existing SKU_001 and add a new SKU_002\n",
        "product_details = update_product_details(product_details, \"SKU_001\", {\"price\": 48000, \"availability\": \"Limited Stock\"})\n",
        "product_details = update_product_details(product_details, \"SKU_002\", {\n",
        "    \"product_name\": \"Smartphone\",\n",
        "    \"brand\": \"ABC\",\n",
        "    \"model\": \"S10\",\n",
        "    \"specifications\": {\"RAM\": \"6GB\", \"Storage\": \"128GB\"},\n",
        "    \"price\": 30000,\n",
        "    \"availability\": \"In Stock\"\n",
        "})\n",
        "\n",
        "print(product_details)\n"
      ],
      "metadata": {
        "id": "GQvyrhp3-t5s",
        "outputId": "2017f96d-0738-4001-bf20-deee8809ac35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SKU_001': {'product_name': 'Laptop', 'brand': 'XYZ', 'model': 'X123', 'specifications': {'RAM': '8GB', 'Storage': '512GB SSD'}, 'price': 48000, 'availability': 'Limited Stock'}, 'SKU_002': {'product_name': 'Smartphone', 'brand': 'ABC', 'model': 'S10', 'specifications': {'RAM': '6GB', 'Storage': '128GB'}, 'price': 30000, 'availability': 'In Stock'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK1tyUi4UDwK"
      },
      "source": [
        "### Checklist\n",
        "- Function `update_product_details()` defined.\n",
        "- Modified the `product_details` dictionary to reflect the newly added or updated product.\n",
        "- Updated `product_details` dictionary returned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbsIu0TT2R4H"
      },
      "source": [
        "## Task 5 - Update product description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLsJVtWtT6Wn"
      },
      "source": [
        "### Description\n",
        "In this task, you will write a function to add a product description for the new product using its product SKU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYE0bb3bT6Wn"
      },
      "source": [
        "### Requirements\n",
        "- Define a function named `update_product_description()` that adds a new product description to or updates an existing product description in the `product_descriptions` dictionary using the SKU as the key.\n",
        "- The function should accept three parameters:\n",
        "  - the `product_descriptions` dictionary,\n",
        "  - the `sku` value, and\n",
        "  - the `description`, a string containing the description of the product.\n",
        "- The function adds the new product description to the `product_descriptions` dictionary with the provided SKU as the key if the SKU does not exist, or updates the existing entry if it does.\n",
        "- Return the updated `product_descriptions` dictionary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gto9F0P82SIv"
      },
      "outputs": [],
      "source": [
        "# def update_product_description(product_descriptions, sku, description):\n",
        "#     \"\"\"\n",
        "#     Adds a new product/updates an existing product description to the product descriptions dictionary using the provided SKU as the key.\n",
        "\n",
        "#     Parameters:\n",
        "#         product_descriptions (dict): The dictionary containing existing product descriptions.\n",
        "#         sku (str): The product SKU.\n",
        "#         description (str): The description of the product.\n",
        "\n",
        "#     Returns:\n",
        "#         dict: The updated product descriptions dictionary with the new or updated product description.\n",
        "#     \"\"\"\n",
        "\n",
        "#     ### CODE HERE ###\n",
        "\n",
        "#     return product_descriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDn1TCSLCr_R"
      },
      "source": [
        "Check your code here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_product_description(product_descriptions, sku, description):\n",
        "    \"\"\"\n",
        "    Updates the product_descriptions dictionary by adding or updating a description for a given SKU.\n",
        "\n",
        "    Parameters:\n",
        "        product_descriptions (dict): The dictionary containing product descriptions.\n",
        "        sku (str): The SKU of the product to be updated.\n",
        "        description (str): A string containing the product description.\n",
        "\n",
        "    Returns:\n",
        "        dict: The updated product_descriptions dictionary.\n",
        "    \"\"\"\n",
        "    # Update if SKU exists, else add new entry\n",
        "    product_descriptions[sku] = description\n",
        "    return product_descriptions\n",
        "\n",
        "# Example Usage\n",
        "product_descriptions = {\n",
        "    \"SKU_001\": \"A high-performance laptop with 8GB RAM and 512GB SSD storage.\",\n",
        "    \"SKU_002\": \"A premium smartphone with 6GB RAM and 128GB storage.\"\n",
        "}\n",
        "\n",
        "# Update description for SKU_001 and add a new SKU_003\n",
        "product_descriptions = update_product_description(product_descriptions, \"SKU_001\", \"A powerful laptop with 16GB RAM and 1TB SSD storage.\")\n",
        "product_descriptions = update_product_description(product_descriptions, \"SKU_003\", \"A budget-friendly smartwatch with multiple fitness tracking features.\")\n",
        "\n",
        "print(product_descriptions)\n"
      ],
      "metadata": {
        "id": "msw9QNze-_iR",
        "outputId": "060a9258-26fc-4a5a-c0fc-b50184c0c830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SKU_001': 'A powerful laptop with 16GB RAM and 1TB SSD storage.', 'SKU_002': 'A premium smartphone with 6GB RAM and 128GB storage.', 'SKU_003': 'A budget-friendly smartwatch with multiple fitness tracking features.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxVoqK32UEpS"
      },
      "source": [
        "### Checklist\n",
        "- Function `update_product_description()` defined\n",
        "- Modified `product_descriptions` dictionary to reflect the newly added or updated description.\n",
        "- Updated `product_descriptions` dictionary returned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5N6bVo82VF3"
      },
      "source": [
        "## Task 6 - Update function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8ACLR0kT65r"
      },
      "source": [
        "### Description\n",
        "In this task, you will write a function that combines the functionalities of adding sales data, product details, and product description for a new product SKU, or updating these for an existing product SKU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLPOHSC5T65r"
      },
      "source": [
        "### Requirements\n",
        "- Define a function named `update()` that collects comprehensive information about a new or existing product from the user, validates the input, and modifies the respective dictionaries with product details, sales data, and product descriptions to reflect the addition or update of the provided product.\n",
        "- The function should accept three parameters:\n",
        "  - `product_details`: A dictionary containing product details. Each entry maps an SKU to its corresponding product details.\n",
        "  - `sales_data`: A dictionary containing sales data. Each entry maps an SKU to a list of sales quantities for the last 14 days.\n",
        "  - `product_descriptions`: A dictionary containing product descriptions. Each entry maps an SKU to its corresponding textual description.\n",
        "- The function performs several operations:\n",
        "  - Prompts the user to input the SKU, which must be exactly 13 characters long. If the SKU does not meet this requirement, print an error message and terminate the function without updating any dictionaries.\n",
        "  - Prompts the user to enter sales data for the last 14 days, which must consist of exactly 14 whole numbers separated by spaces. If the input does not meet this criterion, print an error message and terminate the function without updating any dictionaries.\n",
        "  - Collects product details from the user, including name, brand, model, specifications, price, and availability. These inputs are required but not subject to specific validation criteria for this function.\n",
        "  - Prompts the user for a product description, which is also required for successful product registration.\n",
        "- If all inputs are validated successfully, the function updates the `product_details`, `sales_data`, and `product_descriptions` dictionaries with the provided product information and prints a success message.\n",
        "- Returns a tuple containing the updated `product_details`, `sales_data`, and `product_descriptions` dictionaries in that order.\n",
        "- The function is designed for use when a new product is to be added to the system or when an existing product in the system needs to be updated, and requires the caller to pass the current state of the `product_details`, `sales_data`, and `product_descriptions` dictionaries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdqcaLI1T65s"
      },
      "source": [
        "### Recommendations\n",
        "- You can use if-else statements to check the validity of the data inputted by the user.\n",
        "- Use a list comprehension to prepare the sales data before saving it in the dictionary.\n",
        "- Use the previously defined functions to perform the actions after validating user's input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEyahKVZCtpR"
      },
      "source": [
        "Check your code here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update(product_details, sales_data, product_descriptions):\n",
        "    \"\"\"\n",
        "    Collects product information from the user, validates it, and updates the product details,\n",
        "    sales data, and product descriptions dictionaries.\n",
        "\n",
        "    Parameters:\n",
        "        product_details (dict): Dictionary containing product details.\n",
        "        sales_data (dict): Dictionary containing sales data for the last 14 days.\n",
        "        product_descriptions (dict): Dictionary containing product descriptions.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Updated (product_details, sales_data, product_descriptions) dictionaries.\n",
        "    \"\"\"\n",
        "    # Get SKU input from the user\n",
        "    sku = input(\"Enter the SKU (13 characters long): \").strip()\n",
        "    if len(sku) != 13:\n",
        "        print(\"Error: SKU must be exactly 13 characters long.\")\n",
        "        return product_details, sales_data, product_descriptions\n",
        "\n",
        "    # Get sales data input\n",
        "    sales_input = input(\"Enter sales data for the last 14 days (space-separated whole numbers): \").strip()\n",
        "    sales_values = sales_input.split()\n",
        "\n",
        "    # Validate sales data\n",
        "    if len(sales_values) != 14 or not all(s.isdigit() for s in sales_values):\n",
        "        print(\"Error: Sales data must contain exactly 14 whole numbers separated by spaces.\")\n",
        "        return product_details, sales_data, product_descriptions\n",
        "\n",
        "    # Convert sales values to integers\n",
        "    sales_values = [int(s) for s in sales_values]\n",
        "\n",
        "    # Collect product details\n",
        "    name = input(\"Enter product name: \").strip()\n",
        "    brand = input(\"Enter brand: \").strip()\n",
        "    model = input(\"Enter model: \").strip()\n",
        "    specifications = input(\"Enter specifications: \").strip()\n",
        "\n",
        "    try:\n",
        "        price = float(input(\"Enter price: \").strip())\n",
        "    except ValueError:\n",
        "        print(\"Error: Price must be a valid number.\")\n",
        "        return product_details, sales_data, product_descriptions\n",
        "\n",
        "    availability = input(\"Enter availability (In Stock/Out of Stock): \").strip()\n",
        "\n",
        "    # Collect product description\n",
        "    description = input(\"Enter product description: \").strip()\n",
        "\n",
        "    # Ensure all fields are provided\n",
        "    if not all([name, brand, model, specifications, availability, description]):\n",
        "        print(\"Error: All product details and description fields must be provided.\")\n",
        "        return product_details, sales_data, product_descriptions\n",
        "\n",
        "    # Create product info dictionary\n",
        "    product_info = {\n",
        "        \"name\": name,\n",
        "        \"brand\": brand,\n",
        "        \"model\": model,\n",
        "        \"specifications\": specifications,\n",
        "        \"price\": price,\n",
        "        \"availability\": availability\n",
        "    }\n",
        "\n",
        "    # Update sales data, product details, and product description using previous functions\n",
        "    sales_data = update_sales_data(sales_data, sku, sales_values)\n",
        "    product_details = update_product_details(product_details, sku, product_info)\n",
        "    product_descriptions = update_product_description(product_descriptions, sku, description)\n",
        "\n",
        "    print(\"Product information successfully added/updated.\")\n",
        "\n",
        "    return product_details, sales_data, product_descriptions\n",
        "\n"
      ],
      "metadata": {
        "id": "0_lvABxs_SBI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aC5XgGg0UF4n"
      },
      "source": [
        "### Checklist\n",
        "- Prompt for and validate SKU length (13 characters).\n",
        "- Collected sales data for 14 days and ensure it includes exactly 14 whole numbers.\n",
        "- Gathered product name, brand, model, specifications, price, and availability.\n",
        "- Collected a textual description of the product.\n",
        "- Updated `product_details`, `sales_data`, and `product_descriptions` dictionaries after successful data validation.\n",
        "- Returned the updated dictionaries in the correct order.\n",
        "- Performed all validations before dictionary updates to maintain data integrity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8WDGtEcj_Xn"
      },
      "source": [
        "# Stage 3 - Save data to disk\n",
        "In the this stage, learners are tasked with creating a `dump_data()` function which will allow the newly modified files to be saved in their corresponding file formats: CSV for sales data, JSON for product details, and plain text (.txt) for product descriptions.\n",
        "\n",
        "You will achieve this by completing the following task:\n",
        "- Task 7 - Save data to disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccFlC9OGdejQ"
      },
      "source": [
        "## Task 7 - Save data to disk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqDs8HZ7dYZx"
      },
      "source": [
        "### Description\n",
        "In this task, learners are tasked with implementing a Python function named `dump_data()` that automates the process of persisting sales data, product details, and product descriptions into structured files within a specified directory. The function should efficiently organize and dump each type of data into its corresponding file format: CSV for sales data, JSON for product details, and plain text for product descriptions. This exercise challenges learners to apply file I/O operations, directory management, and data serialization techniques in Python, ensuring they gain practical experience with data persistence, manipulation, and organization on the filesystem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffUjhTwTdYRw"
      },
      "source": [
        "### Requirements\n",
        "- Define a function named `dump_data()` that dumps product details, sales data, and product descriptions into files within a specified main folder.\n",
        "- The function should accept four parameters:\n",
        "  - `sales_data`: A dictionary containing sales data, with SKU as keys and a list of sales quantities for the last 14 days as values.\n",
        "  - `product_details`: A dictionary containing product details, with SKU as keys and details as values. Details include attributes like name, brand, model, specifications, price, and availability.\n",
        "  - `product_descriptions`: A dictionary containing product descriptions, with SKU as keys and the textual description of the product as values.\n",
        "  - `main_folder`: A string representing the location of the main folder, which should contain *product_details* and *product_descriptions* subfolders.\n",
        "- The function performs the following operations:\n",
        "  - Dumps the `sales_data` into a CSV file named *sales_data.csv* located in the *main_folder*. Each row in the CSV file represents the sales data for a product, with fields for the SKU and sales quantities for each of the 14 days.\n",
        "  - Dumps each entry in `product_details` into a separate JSON file within the *product_details* subfolder of the *main_folder*. Each file is named after the SKU of the product and contains the details of that product in JSON format.\n",
        "  - Dumps each product description from `product_descriptions` into a separate TXT file within the *product_descriptions* subfolder of the *main_folder*. Each file is named after the SKU of the product and contains the textual description of that product.\n",
        "- Prior to dumping product details and descriptions, the function checks if the respective subfolders exist. If not, it creates them.\n",
        "- Usage:\n",
        "  - The function is designed to persist the current state of sales data, product details, and product descriptions to the filesystem, allowing for data backup and recovery. It organizes the persisted data into a structured directory and file system based on the specified *main_folder* path.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMuHRcMELNoq"
      },
      "outputs": [],
      "source": [
        "# def dump_data(sales_data, product_details, product_descriptions, main_folder):\n",
        "#     \"\"\"\n",
        "#     Dump product details, sales data, and product descriptions to files.\n",
        "\n",
        "#     Parameters:\n",
        "#         sales_data (dict): The dictionary containing sales data.\n",
        "#         product_details (dict): The dictionary containing product details.\n",
        "#         product_descriptions (dict): The dictionary containing product descriptions.\n",
        "#         main_folder (str): The location of the main folder containing product_details and product_descriptions folders.\n",
        "#     \"\"\"\n",
        "\n",
        "#     ### CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0IRwQvIDAaB"
      },
      "source": [
        "Check your function here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "\n",
        "def dump_data(sales_data, product_details, product_descriptions, main_folder):\n",
        "    \"\"\"\n",
        "    Dumps sales data, product details, and product descriptions into their respective files in the main folder.\n",
        "\n",
        "    Parameters:\n",
        "        sales_data (dict): Dictionary with SKU as keys and a list of sales quantities for the last 14 days as values.\n",
        "        product_details (dict): Dictionary with SKU as keys and details (name, brand, model, etc.) as values.\n",
        "        product_descriptions (dict): Dictionary with SKU as keys and textual descriptions as values.\n",
        "        main_folder (str): Path to the main folder containing product_details and product_descriptions subfolders.\n",
        "    \"\"\"\n",
        "    # Ensure the main folder exists\n",
        "    os.makedirs(main_folder, exist_ok=True)\n",
        "\n",
        "    # Save sales data to sales_data.csv\n",
        "    sales_data_path = os.path.join(main_folder, \"sales_data.csv\")\n",
        "    with open(sales_data_path, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['Product_SKU'] + [f'Day{i+1}' for i in range(14)]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for sku, quantities in sales_data.items():\n",
        "            writer.writerow({'Product_SKU': sku, **{f'Day{i+1}': quantities[i] for i in range(14)}})\n",
        "\n",
        "    # Ensure product details folder exists\n",
        "    product_details_folder = os.path.join(main_folder, \"product_details\")\n",
        "    os.makedirs(product_details_folder, exist_ok=True)\n",
        "\n",
        "    # Save product details as JSON files\n",
        "    for sku, details in product_details.items():\n",
        "        product_details_path = os.path.join(product_details_folder, f\"{sku}.json\")\n",
        "        with open(product_details_path, mode='w', encoding='utf-8') as jsonfile:\n",
        "            json.dump(details, jsonfile, indent=4)\n",
        "\n",
        "    # Ensure product descriptions folder exists\n",
        "    product_descriptions_folder = os.path.join(main_folder, \"product_descriptions\")\n",
        "    os.makedirs(product_descriptions_folder, exist_ok=True)\n",
        "\n",
        "    # Save product descriptions as TXT files\n",
        "    for sku, description in product_descriptions.items():\n",
        "        product_description_path = os.path.join(product_descriptions_folder, f\"{sku}.txt\")\n",
        "        with open(product_description_path, mode='w', encoding='utf-8') as txtfile:\n",
        "            txtfile.write(description)\n",
        "\n",
        "    print(\"Data successfully saved to disk.\")"
      ],
      "metadata": {
        "id": "O149kO4k_21E"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will notice that *mainfolder* now has new files in the product descriptions/details subfolders, as well as new rows in *sales_data.csv* corresponding to the products that you created in stage 2, and while checking your code."
      ],
      "metadata": {
        "id": "3cjHZPLcBt4t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5PVdR8mATvh"
      },
      "source": [
        "### Checklist\n",
        "- Define the `dump_data()` function with the specified parameters.\n",
        "- Saved the sales data, product details and the product description into the respective files.\n",
        "- Ensured that the folder structure remains the same for future use."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}